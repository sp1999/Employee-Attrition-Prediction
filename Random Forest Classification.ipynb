{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Importing libraries\n\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\n\n# Scikit-learn library: For Random Forests\nimport time\nimport random\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier \nfrom urllib.request import urlopen \n\n# Matplotlib library to plot the charts\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\n%matplotlib inline\n\nplt.style.use('ggplot')\npd.set_option('display.max_columns', 500) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.DataFrame(pd.read_csv('../input/ee-769-assignment1/train.csv'))\ntest = pd.DataFrame(pd.read_csv('../input/ee-769-assignment1/test.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop([\"Attrition\", \"EmployeeCount\"],axis=1)\ntest = test.drop(\"EmployeeCount\", axis = 1)\ny = train[\"Attrition\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert objects to numbers by pandas.get_dummies\nX = pd.get_dummies(X, columns=[\"Gender\", \"BusinessTravel\", \"Department\", \"EducationField\", \"JobRole\", \"MaritalStatus\", \"OverTime\"])\nX_test = pd.get_dummies(test, columns=[\"Gender\", \"BusinessTravel\", \"Department\", \"EducationField\", \"JobRole\", \"MaritalStatus\", \"OverTime\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set the random state for reproducibility\nfit_rf = RandomForestClassifier(random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting dataset into training set and validation set for better generalisation\nX_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nstart = time.time()\n\nparam_dist = {'n_estimators': (10,100), 'max_depth': [2, 3, 4, 5],\n              'bootstrap': [True, False],\n              'max_features': ['auto', 'sqrt', 'log2', None],\n              'criterion': ['gini', 'entropy']}\n\ncv_rf = GridSearchCV(fit_rf, cv = 10,\n                     param_grid=param_dist, \n                     n_jobs = 3)\n\ncv_rf.fit(X_train, y_train)\nprint('Best Parameters using grid search: \\n', \n      cv_rf.best_params_)\nend = time.time()\nprint('Time taken in grid search: {0: .2f}'.format(end - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set best parameters given by grid search \nfit_rf.set_params(n_estimators = 100, bootstrap = 'False', criterion = 'gini',\n                  max_features = 'auto', \n                  max_depth = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def variable_importance(fit):\n    \"\"\"\n    Purpose\n    ----------\n    Checks if model is fitted CART model then produces variable importance\n    and respective indices in dictionary.\n\n    Parameters\n    ----------\n    * fit:  Fitted model containing the attribute feature_importances_\n\n    Returns\n    ----------\n    Dictionary containing arrays with importance score and index of columns\n    ordered in descending order of importance.\n    \"\"\"\n    try:\n        if not hasattr(fit, 'fit'):\n            return print(\"'{0}' is not an instantiated model from scikit-learn\".format(fit)) \n\n        # Captures whether the model has been trained\n        if not vars(fit)[\"estimators_\"]:\n            return print(\"Model does not appear to be trained.\")\n    except KeyError:\n        print(\"Model entered does not contain 'estimators_' attribute.\")\n\n    importances = fit.feature_importances_\n    indices = np.argsort(importances)[::-1]\n    return {'importance': importances,\n            'index': indices}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var_imp_rf = variable_importance(fit_rf)\n\nimportances_rf = var_imp_rf['importance']\n\nindices_rf = var_imp_rf['index']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_var_importance(importance, indices, name_index):\n    \"\"\"\n    Purpose\n    ----------\n    Prints dependent variable names ordered from largest to smallest\n    based on information gain for CART model.\n    Parameters\n    ----------\n    * importance: Array returned from feature_importances_ for CART\n                models organized by dataframe index\n    * indices: Organized index of dataframe from largest to smallest\n                based on feature_importances_\n    * name_index: Name of columns included in model\n\n    Returns\n    ----------\n    Prints feature importance in descending order\n    \"\"\"\n    print(\"Feature ranking:\")\n\n    for f in range(0, indices.shape[0]):\n        i = f\n        print(\"{0}. The feature '{1}' has a Mean Decrease in Impurity of {2:.5f}\"\n              .format(f + 1,\n                      list(X_train.columns.values)[indices[i]],\n                      importance[indices[f]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_var_importance(importances_rf, indices_rf, list(X_train.columns.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def variable_importance_plot(importance, indices, names_index):\n    \"\"\"\n    Purpose\n    ----------\n    Prints bar chart detailing variable importance for CART model\n    NOTE: feature_space list was created because the bar chart\n    was transposed and index would be in incorrect order.\n\n    Parameters\n    ----------\n    * importance: Array returned from feature_importances_ for CART\n                models organized by dataframe index\n    * indices: Organized index of dataframe from largest to smallest\n                based on feature_importances_\n    * name_index: Name of columns included in model\n\n    Returns:\n    ----------\n    Returns variable importance plot in descending order\n    \"\"\"\n    index = np.arange(len(names_index))\n\n    importance_desc = sorted(importance)\n    feature_space = []\n    for i in range(indices.shape[0] - 1, -1, -1):\n        feature_space.append(names_index[indices[i]])\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n\n    ax.set_facecolor('#fafafa')\n    plt.title('Feature importances for Random Forest Model\\\n    \\nBreast Cancer (Diagnostic)')\n    plt.barh(index,\n             importance_desc,\n             align=\"center\",\n             color = '#875FDB')\n    plt.yticks(index,\n               feature_space)\n\n    plt.ylim(-1, 30)\n    plt.xlim(0, max(importance_desc) + 0.01)\n    plt.xlabel('Mean Decrease in Impurity')\n    plt.ylabel('Feature')\n\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"variable_importance_plot(importances_rf, indices_rf, list(X_train.columns.values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = fit_rf.predict(X_test)\nres = pd.DataFrame({\"ID\": test[\"ID\"], \"Attrition\": y_pred})\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('output.csv', 'w') as csv_file:\n    res.to_csv(path_or_buf=csv_file, index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}